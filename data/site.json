{
    "site": {
        "title": "Xiangtao Meng | Trustworthy ML",
        "description": "Researcher in trustworthy machine learning, focusing on deepfake forensics and LLM safety.",
        "base_url": "/",
        "theme": "dark"
    },
    "assets": {
        "placeholder_image": "assets/images/mxt.jpg",
        "downloads": {
            "cv": "assets/downloads/cv.pdf"
        },
        "archives": {
            "legacy_jemdoc": "assets/archives/legacy-jemdoc.html"
        }
    },
    "toggles": {
        "news": true,
        "publications": true,
        "projects": true,
        "resources": true,
        "blog": false,
        "essays": false,
        "legacy_archive": false
    },
    "profile": {
        "name": "Xiangtao Meng",
        "native_name": "\u5b5f\u7965\u6d9b",
        "role": "2nd-year Ph.D., School of Cyber Science and Technology",
        "organization": "Shandong University",
        "location": "Qingdao, China",
        "avatar": "assets/images/placeholder.svg",
        "email": "mengxiangtao@mail.sdu.edu.cn",
        "tagline": "Exploring secure and trustworthy AI, from deepfake detection to robust large language models.",
        "socials": [
            {
                "label": "GitHub",
                "url": "https://github.com/AnonymousUserA"
            },
            {
                "label": "Google Scholar",
                "url": "https://scholar.google.com/citations?hl=zh-CN&user=W_GK6gcAAAAJ"
            },
            {
                "label": "ISecLab",
                "url": "https://sduiseclab.github.io/"
            }
        ],
        "actions": [
            {
                "label": "Download CV",
                "url": "assets/downloads/cv.pdf",
                "variant": "btn-primary"
            },
            {
                "label": "Legacy jemdoc archive",
                "url": "assets/archives/legacy-jemdoc.html",
                "variant": "btn-outline",
                "toggle": "legacy_archive"
            }
        ]
    },
    "navigation": [
        {
            "label": "About",
            "target": "#about",
            "enabled": true
        },
        {
            "label": "News",
            "target": "#news",
            "toggle": "news"
        },
        {
            "label": "Publications",
            "target": "#publications",
            "toggle": "publications"
        },
        {
            "label": "Projects",
            "target": "#projects",
            "toggle": "projects"
        },
        {
            "label": "Resources",
            "target": "#resources",
            "toggle": "resources"
        },
        {
            "label": "Blog",
            "target": "#blog",
            "toggle": "blog"
        },
        {
            "label": "Essays",
            "target": "#essays",
            "toggle": "essays"
        },
        {
            "label": "Legacy (jemdoc)",
            "target": "assets/archives/legacy-jemdoc.html",
            "toggle": "legacy_archive",
            "external": true
        }
    ],
    "highlights": [
        {
            "title": "Trustworthy Machine Learning",
            "description": "Researching safety, robustness, and privacy across generative models and LLM agents."
        },
        {
            "title": "Deepfake Forensics",
            "description": "Building attacks and defenses for facial forgery detection in practical pipelines."
        },
        {
            "title": "Secure LLM Systems",
            "description": "Designing evaluation frameworks that expose risk interactions and support safer deployments."
        }
    ],
    "timeline": [
        {
            "date": "2025-11-03",
            "title": "Featured by MIT Technology Review China",
            "description": "Media coverage of our latest LLM defense study.",
            "link": "https://wap.mittrchina.com/news/detail/15426"
        },
        {
            "date": "2025-10-10",
            "title": "Preprint: From Defender to Devil?",
            "description": "Investigating unintended risk interactions introduced by LLM defenses.",
            "link": "https://arxiv.org/abs/2510.07968"
        },
        {
            "date": "2025-09-18",
            "title": "ErrorTrace accepted at NeurIPS 2025 (spotlight)",
            "description": "Black-box traceability based on model family error space.",
            "link": "https://arxiv.org/abs/2509.06026"
        },
        {
            "date": "2025-09-06",
            "title": "Industry collaboration launched",
            "description": "Joint research project on LLM security testing and risk assessment with Topsec."
        },
        {
            "date": "2025-08-28",
            "title": "Preprint: Safe-Control",
            "description": "Safety patch for mitigating unsafe content in text-to-image generation models.",
            "link": "https://arxiv.org/abs/2508.21099"
        },
        {
            "date": "2025-08-13",
            "title": "DCMI accepted at CCS 2025",
            "description": "Differential calibration membership inference against RAG.",
            "link": "https://arxiv.org/abs/2509.06026"
        },
        {
            "date": "2025-03-11",
            "title": "Fuzz-testing meets LLM-based agents accepted at IEEE S&P 2025",
            "description": "Automated framework for jailbreaking text-to-image generation models.",
            "link": "https://arxiv.org/abs/2408.00523"
        },
        {
            "date": "2024-11-15",
            "title": "Outstanding master's thesis",
            "description": "Recognized for thesis on robustness research for deepfake detection."
        }
    ],
    "publications": [
        {
            "title": "From Defender to Devil? Unintended Risk Interactions Induced by LLM Defenses",
            "authors": "Xiangtao Meng, Tianshuo Cong, Li Wang, Wenyu Chen, Zheng Li\u2709, Shanqing Guo\u2709, Xiaoyun Wang\u2709",
            "venue": "arXiv",
            "year": 2025,
            "highlights": [
                "LLM Safety",
                "Risk Analysis"
            ],
            "links": {
                "paper": "https://arxiv.org/abs/2510.07968"
            }
        },
        {
            "title": "ErrorTrace: A Black-Box Traceability Mechanism Based on Model Family Error Space",
            "authors": "Chuanchao Zang, Xiangtao Meng, Wenyu Chen, Tianshuo Cong, Zha Yaxing, Dong Qi, Zheng Li, Shanqing Guo",
            "venue": "NeurIPS (Spotlight)",
            "year": 2025,
            "highlights": [
                "Model Provenance",
                "NeurIPS 2025"
            ],
            "links": {}
        },
        {
            "title": "Safe-Control: A Safety Patch for Mitigating Unsafe Content in Text-to-Image Generation Models",
            "authors": "Xiangtao Meng, Yingkai Dong, Ning Yu, Li Wang, Zheng Li\u2709, Shanqing Guo\u2709",
            "venue": "arXiv",
            "year": 2025,
            "highlights": [
                "T2I Safety",
                "Defense"
            ],
            "links": {
                "paper": "https://arxiv.org/abs/2508.21099"
            }
        },
        {
            "title": "DCMI: A Differential Calibration Membership Inference Attack Against Retrieval-Augmented Generation",
            "authors": "Xinyu, Xiangtao Meng\u2709, Yingkai Dong, Zheng Li\u2709, Shanqing Guo\u2709",
            "venue": "CCS",
            "year": 2025,
            "highlights": [
                "RAG Security",
                "CCS 2025"
            ],
            "links": {
                "paper": "https://arxiv.org/abs/2509.06026"
            }
        },
        {
            "title": "Fuzz-testing meets LLM-based agents: An automated and efficient framework for jailbreaking text-to-image generation models",
            "authors": "Yingkai Dong, Xiangtao Meng, Ning Yu, Li Wang, Zheng Li\u2709, Shanqing Guo\u2709",
            "venue": "IEEE S&P",
            "year": 2025,
            "highlights": [
                "Adversarial Testing",
                "IEEE S&P"
            ],
            "links": {
                "paper": "https://arxiv.org/abs/2408.00523"
            }
        },
        {
            "title": "AVA: Inconspicuous Attribute Variation-based Adversarial Attack bypassing DeepFake Detection",
            "authors": "Xiangtao Meng, Li Wang, Shanqing Guo\u2709, Lei Ju, Qingchuan Zhao",
            "venue": "IEEE S&P",
            "year": 2024,
            "highlights": [
                "Deepfake Attack",
                "Code Released"
            ],
            "links": {
                "paper": "https://arxiv.org/abs/2312.08675",
                "code": "https://github.com/AnonymousUserA/AVA"
            }
        },
        {
            "title": "DEEPFAKER: A Unified Evaluation Platform for Facial Deepfake and Detection Models",
            "authors": "Li Wang, Xiangtao Meng, Dan Li, Xuhong Zhang, Shouling Ji, Shanqing Guo\u2709",
            "venue": "ACM TOPS",
            "year": 2024,
            "highlights": [
                "Benchmark",
                "CCF B"
            ],
            "links": {
                "paper": "https://dl.acm.org/doi/abs/10.1145/3634914"
            }
        }
    ],
    "projects": [
        {
            "name": "LLM Security Testing Framework",
            "summary": "Joint research with Topsec to design systematic testing and risk assessment for large language models.",
            "tags": [
                "LLM Security",
                "Industry Collaboration"
            ],
            "image": "assets/images/placeholder.svg"
        },
        {
            "name": "Safe-Control",
            "summary": "Safety patch for grounding text-to-image generation within controllable boundaries.",
            "tags": [
                "Defense",
                "Generative AI"
            ],
            "image": "assets/images/placeholder.svg"
        },
        {
            "name": "ErrorTrace",
            "summary": "Tracing model lineage through error space signatures in black-box settings.",
            "tags": [
                "Traceability",
                "NeurIPS 2025"
            ],
            "image": "assets/images/placeholder.svg"
        },
        {
            "name": "DCMI",
            "summary": "Membership inference against retrieval-augmented generation via differential calibration.",
            "tags": [
                "Privacy",
                "CCS 2025"
            ],
            "image": "assets/images/placeholder.svg"
        },
        {
            "name": "DEEPFAKER",
            "summary": "Unified evaluation platform covering facial deepfake generation and detection models.",
            "tags": [
                "Benchmark",
                "TOPS"
            ],
            "image": "assets/images/placeholder.svg"
        }
    ],
    "resources": [
        {
            "category": "Tutorials",
            "items": [
                {
                    "title": "Ubuntu \u5229\u7528Github\u914d\u7f6e\u4e2a\u4eba\u4e3b\u9875(jemdoc)",
                    "url": "https://www.notion.so/Ubuntu-Github-dc04221847994d65834290470e394777",
                    "note": "\u73af\u5883\u914d\u7f6e\u8bb0\u5f55"
                },
                {
                    "title": "Anaconda \u7684\u4f7f\u7528\u6559\u7a0b",
                    "url": "https://www.notion.so/Anaconda-21b9d59fb67146bba32feeedaadce461"
                },
                {
                    "title": "\u5b89\u5168\u9876\u4f1a\u67e5\u8be2\u6559\u7a0b",
                    "url": "https://www.notion.so/cc157d48f8fb4073a7432657bdb6e9d7"
                },
                {
                    "title": "Windows \u4e0a\u4f20\u6587\u4ef6\u5230\u8fdc\u7a0b\u670d\u52a1\u5668",
                    "url": "https://www.notion.so/add0ff2720624f5e96cee6dce0820594"
                }
            ]
        },
        {
            "category": "Research Notes",
            "items": [
                {
                    "title": "Kaldi \u5b89\u88c5\u53ca ASpIRE \u6a21\u578b\u7684\u4f7f\u7528",
                    "url": "https://www.notion.so/Kaldi-ASpIRE-34aa438f43a6449b8501df72aa14c49f"
                },
                {
                    "title": "\u8bed\u97f3\u5bf9\u6297\u4e2d\u503c\u5f97\u6536\u85cf\u7684\u6587\u7ae0",
                    "url": "https://www.notion.so/534a7912d8fe43498e4131ed204dc103"
                },
                {
                    "title": "\u667a\u80fd\u5408\u7ea6\u653b\u51fb\u65b9\u5f0f\u603b\u7ed3",
                    "url": "https://www.notion.so/51e6c16fbaae4b5ea035b680f8e75632"
                },
                {
                    "title": "\u7269\u8054\u7f51\u5b89\u5168\u6001\u52bf\u611f\u77e5\u7cfb\u7edf\u7684\u7814\u7a76\u4e0e\u5b9e\u73b0",
                    "url": "https://www.notion.so/476fc444867c4cc4a6debd2c1d9a42ee"
                },
                {
                    "title": "\u57fa\u4e8e\u79cd\u5b50\u5730\u5740\u7684IPv6\u5730\u5740\u63a2\u6d4b\u6280\u672f",
                    "url": "https://www.notion.so/IPv6-92c43a0fd43b4a21b99997231c159b57"
                },
                {
                    "title": "Intriguing properties of neural networks (L-BFGS \u5f00\u5c71\u4e4b\u4f5c)",
                    "url": "https://www.notion.so/Intriguing-properties-of-neural-networks-L-BFGS-7a65e750d8c14f698a995d41ce95cacf"
                },
                {
                    "title": "CommanderSong \u8bed\u97f3\u5bf9\u6297\u7ecf\u5178\u4e4b\u4f5c",
                    "url": "https://www.notion.so/CommanderSong-6a8ae90ba1694dcabaccf149fc4b580c"
                },
                {
                    "title": "Devil's Whisper \u7269\u7406\u8bed\u97f3\u653b\u51fb",
                    "url": "https://www.notion.so/Devil-s-Whisper-A-General-Approach-for-Physical-Adversarial-Attacks-against-Commercial-Black-box-Spe-e598291f176f43e5882cdf2c28733692"
                },
                {
                    "title": "\u8bed\u97f3\u653b\u51fb\u7c7b\u8bba\u6587\u6c47\u603b\u6574\u7406",
                    "url": "https://www.notion.so/4bbdf4d59eeb4b61a656178a0f1a59b8"
                },
                {
                    "title": "TXSPECTOR: Uncovering Attacks in Ethereum from Transactions",
                    "url": "https://www.notion.so/TxSpector-USENIX-Security-69703e1f1a7841118443232af966fd08"
                },
                {
                    "title": "VULTRON: Catching Vulnerable Smart Contracts",
                    "url": "https://www.notion.so/VULTRON-62707143bab54c7da88bffbef5cfd1e"
                }
            ]
        }
    ],
    "writings": {
        "blog": {
            "eyebrow": "Updates",
            "title": "Blog",
            "description": "Longer notes and experiments that complement formal publications.",
            "entries": [
                {
                    "title": "LLM \u5b89\u5168\u8d8b\u52bf\u89c2\u5bdf",
                    "summary": "Quarterly observations on alignment, jailbreaks, and mitigation patterns in the LLM ecosystem.",
                    "date": "2025-07-12",
                    "url": "https://example.com/blog/llm-safety-trends",
                    "badges": [
                        "Blog"
                    ]
                },
                {
                    "title": "Red-teaming \u7684\u5e38\u89c1\u76f2\u70b9",
                    "summary": "A compact checklist for avoiding coverage gaps when probing multimodal models.",
                    "date": "2025-06-02",
                    "url": "https://example.com/blog/redteam-notes",
                    "badges": [
                        "Notes"
                    ]
                }
            ],
            "archive_link": "https://example.com/blog"
        },
        "essays": {
            "eyebrow": "\u968f\u7b14",
            "title": "Essays",
            "description": "Personal essays and reflections on trustworthy AI.",
            "entries": [
                {
                    "title": "\u7814\u7a76\u4e0e\u4ea7\u54c1\u4e4b\u95f4\u7684\u8ddd\u79bb",
                    "summary": "A short take on connecting security research prototypes to production deployments.",
                    "date": "2025-05-16",
                    "url": "https://example.com/essays/research-to-product",
                    "badges": [
                        "Essay"
                    ]
                },
                {
                    "title": "\u5b89\u5168\u5de5\u4f5c\u7684\u8282\u594f",
                    "summary": "Notes on balancing shipping speed with methodical risk reviews.",
                    "date": "2025-03-28",
                    "url": "https://example.com/essays/security-cadence",
                    "badges": [
                        "Essay",
                        "Team"
                    ]
                }
            ],
            "archive_link": "https://example.com/essays"
        }
    },
    "archives": {
        "legacy_jemdoc": {
            "label": "Legacy jemdoc profile",
            "summary": "Older jemdoc-based pages have been archived for reference only.",
            "url": "assets/archives/legacy-jemdoc.html"
        }
    },
    "footer": {
        "links": [
            {
                "label": "GitHub",
                "url": "https://github.com/AnonymousUserA"
            },
            {
                "label": "Google Scholar",
                "url": "https://scholar.google.com/citations?hl=zh-CN&user=W_GK6gcAAAAJ"
            },
            {
                "label": "ISecLab",
                "url": "https://sduiseclab.github.io/"
            }
        ],
        "note": "Last updated with a lightweight static build pipeline."
    }
}
